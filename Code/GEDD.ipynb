{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cae73fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt, animation\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "import math\n",
    "from scipy.io import savemat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143b429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def break_large_comp(comp,input_user_size):\n",
    "    new_cont = []\n",
    "    rem_cont = []\n",
    "    tmp      = list(comp)\n",
    "    l        = len(comp)\n",
    "    dec,mod = math.modf(l/input_user_size) \n",
    "    for j in range(0,int(mod)):\n",
    "        tmp2 = tmp[j*input_user_size: (j+1)*input_user_size ]  \n",
    "        new_cont.append(tmp2)\n",
    "    if(dec>0):\n",
    "        tmp3 = tmp[ int(mod)*input_user_size:  ]\n",
    "        rem_cont.append(tmp3)\n",
    "    return new_cont, rem_cont\n",
    "\n",
    "\n",
    "#A function to break large graph into smaller subgraphs \n",
    "def create_small_graphs(comp,input_user_size):\n",
    "    \n",
    "    \n",
    "    new_cont = []\n",
    "    rem_cont = []\n",
    "    for i in range(len(comp)):\n",
    "        \n",
    "        l = len(comp[i])\n",
    "        if(l == input_user_size ): # first condition--> cluster size equal to input size\n",
    "            new_cont.append(list(comp[i]))\n",
    "        if(l < input_user_size ): #second condition-->cluster size less than input size\n",
    "            rem_cont.append(comp[i])\n",
    "        if(l > input_user_size ): #third condition --> cluster size more than input size\n",
    "            \n",
    "            new_c,rem_c = break_large_comp(comp[i],input_user_size)\n",
    "            for item in new_c:\n",
    "                new_cont.append(item)\n",
    "            for item in rem_c:\n",
    "                rem_cont.append(item)\n",
    "            \n",
    "    tmp = []\n",
    "    for a in rem_cont:\n",
    "        tmp.extend(a)\n",
    "    \n",
    "    new_c,rem_c = break_large_comp(tmp,input_user_size)\n",
    "    for item in new_c:\n",
    "        new_cont.append(item)\n",
    "    \n",
    "    return new_cont,rem_c\n",
    "    \n",
    "def create_Duplicate_Padding(A_sms,index,input_user_size):\n",
    "    ll                         = len(index)\n",
    "    sub                        = A_sms[np.ix_(index,index)]\n",
    "    pad                        = input_user_size-ll     \n",
    "    \n",
    "    if(pad<=ll):\n",
    "        A_new                      = np.zeros((input_user_size,input_user_size))\n",
    "        A_new[0:ll,0:ll]           = sub\n",
    "        A_new[ll:ll+pad,ll:ll+pad] = sub[0:pad,0:pad]\n",
    "        user_list                  = np.append(index, index[0:pad])\n",
    "    if(pad>ll):\n",
    "        r          = math.ceil(pad/ll)+1\n",
    "        tmp        = np.kron(np.eye(r,dtype=int),sub) # r is number of repeats\n",
    "        tmp2       = np.tile(index,r) \n",
    "        \n",
    "      \n",
    "        A_new      = tmp[0:input_user_size,0:input_user_size]\n",
    "        user_list  = tmp2[0:input_user_size]        \n",
    "    \n",
    "    return user_list,A_new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9aca7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main GEDD loop to generate graphs\n",
    "\n",
    "\n",
    "Storage_cont_call = []\n",
    "Storage_cont_sms  = []\n",
    "user_size         = 10   ## model's required size\n",
    "sms_file_name     = 'sms_graph.pkl'    #provide path to sms and call graphs\n",
    "call_file_name    = 'call_graph.pkl'    #provide path to sms and call graphs\n",
    "sms_files         = pd.read_pickle(sms_file_name)\n",
    "call_files        = pd.read_pickle(call_file_name)\n",
    "\n",
    "for i in range(0,sms_files.shape[0]):\n",
    "   \n",
    "   \n",
    "    user_list           = sms_files.usr_list[i]\n",
    "    start_date          = sms_files.start_date[i]\n",
    "    end_date            = sms_files.end_date[i]\n",
    "    N                   = user_list.size\n",
    "    A_sms               = sms_files.A_msg[i]\n",
    "    A_call              = call_files.A_call[i]\n",
    "    \n",
    "    \n",
    "    ## Processing CALL DATA\n",
    "    \n",
    "    # construct call graph and get connected components\n",
    "    G_call = nx.from_numpy_matrix(A_call)\n",
    "    sg_call = nx.connected_components(G_call)\n",
    "    comp_call = []\n",
    "    for c in sg_call: \n",
    "        comp_call.append(c)\n",
    "    \n",
    "    # FOR CALL : Break the components into user_input_size\n",
    "    \n",
    "    new_gr,rem_gr =  create_small_graphs(comp_call,user_size)\n",
    "    \n",
    "    # Get subgraphs for each sub-comp\n",
    "    for tmp in new_gr:\n",
    "        \n",
    "        DF_call = {'usr_list':user_list, 'A_msg' :A_call[np.ix_(tmp,tmp)] , 'start_date': start_date, 'end_date': end_date}\n",
    "        Storage_cont_call.append(DF_call)\n",
    "        \n",
    "    if(len(rem_gr)>0):\n",
    "        tmp, A_pad = create_Duplicate_Padding(A_call,rem_gr[0],user_size)\n",
    "        DF_call = {'usr_list':user_list, 'A_msg' :A_pad , 'start_date': start_date, 'end_date': end_date}\n",
    "        Storage_cont_call.append(DF_call)\n",
    "\n",
    "   ## Processing SMS DATA\n",
    "    \n",
    "    # construct call graph and get connected components\n",
    "    G_sms = nx.from_numpy_matrix(A_sms)\n",
    "    sg_sms = nx.connected_components(G_sms)\n",
    "    comp_sms = []\n",
    "    for c in sg_sms: \n",
    "        comp_sms.append(c)\n",
    "    \n",
    "    # FOR SMS : Break the components into user_input_size\n",
    "    \n",
    "    new_gr,rem_gr =  create_small_graphs(comp_sms,user_size)\n",
    "    \n",
    "    # Get subgraphs for each sub-comp\n",
    "    for tmp in new_gr:\n",
    "        \n",
    "        DF_sms = {'usr_list':user_list, 'A_msg' :A_sms[np.ix_(tmp,tmp)] , 'start_date': start_date, 'end_date':  end_date}\n",
    "        Storage_cont_sms.append(DF_sms)\n",
    "        \n",
    "    if(len(rem_gr)>0):\n",
    "        tmp, A_pad = create_Duplicate_Padding(A_sms,rem_gr[0],user_size)\n",
    "        DF_sms = {'usr_list':user_list, 'A_msg' :A_pad , 'start_date': start_date, 'end_date':  end_date}\n",
    "        Storage_cont_sms.append(DF_sms)\n",
    "        \n",
    "Output_call = pd.DataFrame(Storage_cont_call)\n",
    "Output_sms  = pd.DataFrame(Storage_cont_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3b1a7261",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save graphs in local folder for use in models later on\n",
    "Output_call.to_pickle(\"A_call_local_10.pkl\")\n",
    "Output_sms.to_pickle(\"A_sms_local_10.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('care')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1aea8e18d1411a1091f0fbde6e4555515247ec3694a44440affbaf196875acfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
