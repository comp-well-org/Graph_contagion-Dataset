{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bcc962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "## Main functions to call\n",
    "from Models_benchmarks import *\n",
    "from Preprocess import *\n",
    "from Performance_Metric import *\n",
    "import time\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0a111d-46ff-4cae-a789-bb6596db240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_loop(trials,BatchSize,X_seq_a,X_cor_a,X_feat_a,y_a,test_size,train_size,num_users,usr_list ):\n",
    "    gcn_df          = pd.DataFrame(columns = ['Metric', 'Avg', 'std','max','min','trial'])\n",
    "    conv_df         = pd.DataFrame(columns = ['Metric', 'Avg', 'std','max','min','trial'])\n",
    "    dump_gcn        = []\n",
    "    dump_bench      = []\n",
    "    dump_benchL     = []\n",
    "    dump_true       = []\n",
    "    dump_cor        = []\n",
    "    train_y         = []\n",
    "    dump_usr        = []\n",
    "\n",
    "\n",
    "    for i in range(0,trials):\n",
    "        X_train_feat, X_train_seq, X_train_lap,y_train, scaler_y, X_valid_feat, X_valid_seq,X_valid_lap, y_valid, X_test_feat,X_test_seq, X_test_lap, y_test, X_test_cor,tmp,usr_test = split_scale(X_seq_a,X_cor_a,X_feat_a,y_a,test_size,train_size,num_users,usr_list)  \n",
    "        pred_gcn,pred_cnv,pred_lstm, history,history_cnv,history_lstm = get_prediction_results(BatchSize,X_train_seq, X_train_lap, X_train_feat, y_train,X_valid_seq, X_valid_lap, X_valid_feat, y_valid,X_test_seq, X_test_lap, X_test_feat,scaler_y,num_users)\n",
    "        true = scaler_y.inverse_transform(y_test)\n",
    "        y_train = scaler_y.inverse_transform(y_train)\n",
    "        dump_gcn.append(pred_gcn)\n",
    "        dump_bench.append(pred_cnv)\n",
    "        dump_benchL.append(pred_lstm)\n",
    "        dump_true.append(true)\n",
    "        dump_cor.append(X_test_cor)\n",
    "        train_y.append(y_train)\n",
    "        dump_usr.append(usr_test)\n",
    "    return dump_gcn,dump_bench,dump_true,dump_cor,train_y,dump_usr,dump_benchL,history,history_lstm,history_cnv\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaeaf8e-8d53-4d11-a7a0-e08e9ff02566",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph_sz    = [10,15]  ## graph size\n",
    "seq_arr     = [3,5,7]   ## sequence length in terms of number of days\n",
    "label_index = 2 #  2:happiness, 3:stress\n",
    "y_id        = \"y_\".format(label_index)\n",
    "test_size   = 0.4\n",
    "train_size  = 0.6\n",
    "trials      = 11\n",
    "BatchSize   = 10\n",
    "\n",
    "gcn_l       = pd.DataFrame(columns=['x', 'f1'])\n",
    "bench_l     = pd.DataFrame(columns=['x', 'f1'])\n",
    "dump_gcn    = []\n",
    "dump_bench  = []\n",
    "dump_benchL  = []\n",
    "dump_true   = []\n",
    "dump_cor    = []\n",
    "train_y     = []\n",
    "dump_usr    = []\n",
    "root            = Path(\".\") ## adjust path according to where data is placed\n",
    "root1 = '/Users/maryamkhalid/Research_Emotion_Recognition/Research Spring 2022/GCN_CONV_LSTM_Feb_8'\n",
    "\n",
    "start = time.time()\n",
    "for gr in graph_sz:\n",
    "    num_users = gr\n",
    "    for seq in seq_arr:\n",
    "        \n",
    "        print(\"graph : \",gr, \" seq : \",seq)\n",
    "        file_name   = \"GraphSeq\"+str(gr)+\"_\"+str(seq)+\".pkl\"\n",
    "        my_path     = root1 + '/' + 'extracted_data'+ '/'+file_name ## path to where extracted data is stored\n",
    "        data_file   = open(my_path,'rb')\n",
    "        unfold      = pickle.load(data_file)\n",
    "        X_seq_a     = unfold[\"X_seq_a\"]\n",
    "        X_cor_a     = unfold[\"X_cor_a\"]\n",
    "        X_feat_a    = unfold[\"X_feat_a\"]\n",
    "        Y           = unfold[\"Y\"]\n",
    "        y_a         = Y[y_id]\n",
    "        usr_list    = unfold[\"usr_id\"]\n",
    "        \n",
    "        ## train the models and obtain predictions for test data\n",
    "        dump_gcn1,dump_bench1,dump_true1,dump_cor1,y_tr,dump_test1,dump_benchL1,_,_,_ = train_model_loop(trials,BatchSize,X_seq_a,X_cor_a,X_feat_a,y_a,test_size,train_size,num_users,usr_list)\n",
    "        dump_gcn.append(dump_gcn1)\n",
    "        dump_bench.append(dump_bench1)\n",
    "        dump_benchL.append(dump_benchL1)\n",
    "        dump_true.append(dump_true1)\n",
    "        dump_cor.append(dump_cor1)\n",
    "        train_y.append(y_tr)\n",
    "        dump_usr.append(dump_test1)\n",
    "        \n",
    "        \n",
    "        x_metr            = ['degree','close','eigen','between','comm','pagerank']\n",
    "        col_name          = x_metr \n",
    "        y_col             = ['yp','yt','usr']\n",
    "        col_name.extend(y_col)\n",
    "        gcn_df            = pd.DataFrame(columns=col_name)\n",
    "        conv_df           = pd.DataFrame(columns=col_name)\n",
    "        lstm_df           = pd.DataFrame(columns=col_name)\n",
    "        outer_loop        = len(dump_gcn)\n",
    "\n",
    "        for i in range(0,outer_loop):\n",
    "            for j in range(0,trials):\n",
    "                main_df  = generate_multi_x_metric_mat(dump_true[i][j],dump_gcn[i][j],dump_cor[i][j],dump_usr[i][j],x_metr)\n",
    "                gcn_df   = gcn_df.append(main_df,ignore_index = True)  ## Proposed model output metrics\n",
    "            \n",
    "        for i in range(0,outer_loop):\n",
    "            for j in range(0,trials):\n",
    "                main_dfc  = generate_multi_x_metric_mat(dump_true[i][j],dump_bench[i][j],dump_cor[i][j],dump_usr[i][j],x_metr)\n",
    "                conv_df    = conv_df.append(main_dfc,ignore_index = True) ## benchmark conv-lstm output metrics\n",
    "            \n",
    "        for i in range(0,outer_loop):\n",
    "            for j in range(0,trials):\n",
    "                main_dfl  = generate_multi_x_metric_mat(dump_true[i][j],dump_benchL[i][j],dump_cor[i][j],dump_usr[i][j],x_metr)\n",
    "                lstm_df    = lstm_df.append(main_dfl,ignore_index = True)  ## benchmark lstm output metrics\n",
    "\n",
    "\n",
    "## save results in the folder Results\n",
    "        file_name1 = \"GCNloop\"+str(gr )+\"_\"+str(seq)+\"_\"+str(trials)+'_'+str(label_index)+\".pkl\"\n",
    "        my_path1   = root / \"Results\" / file_name1  ## folder to save results df containing centrality metrics, true (yt) and predicted (yp) labels for each user\n",
    "        data = {\"gcn_df\":gcn_df,\"conv_df\":conv_df, \"lstm_df\":lstm_df }\n",
    "        with my_path1.open('wb') as fp:\n",
    "            pickle.dump(data, fp)\n",
    "   \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mk-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f80aaba666fc8a099108d9198e276af468c67d15dcbb14a438ec7ce588457f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
